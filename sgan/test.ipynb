{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pandas as pd\n",
    "from utils import load, save, train, DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict()\n",
    "params['DATA_DIR']='sample'\n",
    "params['IMG_DIR'] = '../../data/images'\n",
    "params['GPU_ID']='0' \n",
    "params['EMBEDDDIM'] = (100,200)\n",
    "params['DATAFOLDS'] = 5\n",
    "params['CUDA']=False \n",
    "params['WORKERS']=4\n",
    "params['Z_DIM']=100\n",
    "params['LR_DECAY_EPOCH']=20\n",
    "params['STAGE']=1\n",
    "params['IMGSIZE1']=64\n",
    "params['IMGSIZE2']=255\n",
    "params['MAX_EPOCH']=2\n",
    "params['BATCH_SIZE']=128\n",
    "params['SNAPSHOT_INTERVAL']=1\n",
    "params['DISCRIMINATOR_LR']=0.0002\n",
    "params['GENERATOR_LR']=0.0002\n",
    "params['DF_DIM']=96\n",
    "params['GF_DIM']=192\n",
    "params['CONDITION_DIM'] = 128\n",
    "params['DIMENSION']=1024\n",
    "params['R_NUM'] = 4\n",
    "params['STAGE1_G']='../output/coco_stageI/Model/netG_epoch_120.pth'\n",
    "args= params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DataSet(args)\n",
    "dl = torch.utils.data.DataLoader(ds,batch_size=32,shuffle=True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "0%|          | 0/2 [00:00<?, ?it/s]\n#######################\n#   Running epoch:0...\n#######################\n\n\n##############################\n#   Currently running batch 0\n##############################\n\n\n##############################################################\n#   Current Loss Gen:3.776416540145874 Dis:1.5794665813446045\n##############################################################\n\n\n##############################\n#   Currently running batch 1\n##############################\n\n\n##############################################################\n#   Current Loss Gen:11.244370460510254 Dis:2.503308057785034\n##############################################################\n\n\n##############################\n#   Currently running batch 2\n##############################\n\n\n#############################################################\n#   Current Loss Gen:9.90965461730957 Dis:0.2472333014011383\n#############################################################\n\n\n##############################\n#   Currently running batch 3\n##############################\n\n\n###############################################################\n#   Current Loss Gen:10.641162872314453 Dis:1.1872031688690186\n###############################################################\n\n\n##############################\n#   Currently running batch 4\n##############################\n\n\n################################################################\n#   Current Loss Gen:10.180601119995117 Dis:0.47204434871673584\n################################################################\n\n\n##############################\n#   Currently running batch 5\n##############################\n\n\n###############################################################\n#   Current Loss Gen:15.986796379089355 Dis:0.8806189298629761\n###############################################################\n\n\n##############################\n#   Currently running batch 6\n##############################\n\n\n##############################################################\n#   Current Loss Gen:14.772162437438965 Dis:0.318670392036438\n##############################################################\n\n\n##############################\n#   Currently running batch 7\n##############################\n\n 50%|█████     | 1/2 [02:39<02:39, 159.66s/it]\n##############################################################\n#   Current Loss Gen:6.6388139724731445 Dis:0.347588449716568\n##############################################################\n\nEpoch:0,   G_loss:10.393747299909592,   D_loss:0.9420166537165642\n\n#######################\n#   Running epoch:1...\n#######################\n\n\n##############################\n#   Currently running batch 0\n##############################\n\n\n##############################################################\n#   Current Loss Gen:29.71198844909668 Dis:1.5749562978744507\n##############################################################\n\n\n##############################\n#   Currently running batch 1\n##############################\n\n\n################################################################\n#   Current Loss Gen:32.843177795410156 Dis:0.16248251497745514\n################################################################\n\n\n##############################\n#   Currently running batch 2\n##############################\n\n\n################################################################\n#   Current Loss Gen:27.817729949951172 Dis:0.32843297719955444\n################################################################\n\n\n##############################\n#   Currently running batch 3\n##############################\n\n\n#############################################################\n#   Current Loss Gen:29.3949031829834 Dis:3.9648280143737793\n#############################################################\n\n\n##############################\n#   Currently running batch 4\n##############################\n\n\n###############################################################\n#   Current Loss Gen:23.664512634277344 Dis:1.1020346879959106\n###############################################################\n\n\n##############################\n#   Currently running batch 5\n##############################\n\n\n#############################################################\n#   Current Loss Gen:28.36272430419922 Dis:4.218392372131348\n#############################################################\n\n\n##############################\n#   Currently running batch 6\n##############################\n\n\n###############################################################\n#   Current Loss Gen:17.746732711791992 Dis:1.7220377922058105\n###############################################################\n\n\n##############################\n#   Currently running batch 7\n##############################\n\n100%|██████████| 2/2 [04:53<00:00, 146.92s/it]\n##############################################################\n#   Current Loss Gen:19.275592803955078 Dis:9.084105491638184\n##############################################################\n\nEpoch:1,   G_loss:26.10217022895813,   D_loss:2.7696587685495615\n\n#######################################################\n#   Model training took {(time.time()-start)/60} mins.\n#######################################################\n\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(STAGE1_G(\n   (t2o): T2O(\n     (model): Sequential(\n       (0): Conv1d(100, 32, kernel_size=(10,), stride=(1,))\n       (1): Flatten()\n       (2): Linear(in_features=6112, out_features=1024, bias=True)\n       (3): ReLU()\n     )\n   )\n   (ca_net): CA_NET(\n     (fc): Linear(in_features=1024, out_features=256, bias=True)\n     (relu): ReLU()\n   )\n   (fc): Sequential(\n     (0): Linear(in_features=356, out_features=24576, bias=False)\n     (1): BatchNorm1d(24576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (2): ReLU(inplace=True)\n   )\n   (upsample1): Sequential(\n     (0): Upsample(scale_factor=2.0, mode=nearest)\n     (1): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (3): ReLU(inplace=True)\n   )\n   (upsample2): Sequential(\n     (0): Upsample(scale_factor=2.0, mode=nearest)\n     (1): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (3): ReLU(inplace=True)\n   )\n   (upsample3): Sequential(\n     (0): Upsample(scale_factor=2.0, mode=nearest)\n     (1): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (3): ReLU(inplace=True)\n   )\n   (upsample4): Sequential(\n     (0): Upsample(scale_factor=2.0, mode=nearest)\n     (1): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (3): ReLU(inplace=True)\n   )\n   (img): Sequential(\n     (0): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (1): Tanh()\n   )\n ),\n STAGE1_D(\n   (encode_img): Sequential(\n     (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n     (1): LeakyReLU(negative_slope=0.2, inplace=True)\n     (2): Conv2d(96, 192, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n     (3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (4): LeakyReLU(negative_slope=0.2, inplace=True)\n     (5): Conv2d(192, 384, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n     (6): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (7): LeakyReLU(negative_slope=0.2, inplace=True)\n     (8): Conv2d(384, 768, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n     (9): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (10): LeakyReLU(negative_slope=0.2, inplace=True)\n   )\n   (outlogits): Sequential(\n     (0): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (1): LeakyReLU(negative_slope=0.2, inplace=True)\n     (2): Conv2d(768, 1, kernel_size=(4, 4), stride=(4, 4))\n     (3): Flatten()\n     (4): Sigmoid()\n   )\n ))"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train(dl,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594381526769",
   "display_name": "Python 3.7.7 64-bit ('RemixArt': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}